{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor as MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_data = pd.read_csv(\"trial_data.csv\")\n",
    "# data = list()\n",
    "# for i in range(len(original_data)):\n",
    "#     temp = list()\n",
    "#     temp.append(original_data.iloc[i,0])\n",
    "#     temp.append(original_data.iloc[i,1])\n",
    "#     list_data = ast.literal_eval(original_data.iloc[i,2])\n",
    "#     temp.append(list_data)\n",
    "#     temp.append(ast.literal_eval(original_data.iloc[i,3]))\n",
    "#     data.append(temp)\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df.head(5))\n",
    "# X = df.iloc[:,2]\n",
    "# print(X.head())\n",
    "# y = df.iloc[:,3]\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series_data = X\n",
    "# targets = y\n",
    "\n",
    "# data = pd.DataFrame({'time_series_data': time_series_data, 'target': targets})\n",
    "\n",
    "# X = np.array(data['time_series_data'].tolist())  # Convert the list of lists to a numpy array\n",
    "# y = np.array(data['target'].tolist())\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train, X_test, y_test, subject_number): \n",
    "    print(\"Training for Subject number: \",subject_number)   \n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Create a custom dataset\n",
    "    class CustomDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx], self.y[idx]\n",
    "\n",
    "    # Create DataLoader\n",
    "    # train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    # val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Define your neural network model\n",
    "    class TimeSeriesRegressor(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(TimeSeriesRegressor, self).__init__()\n",
    "            self.fc1 = nn.Linear(1416, 1000)\n",
    "            self.fc2 = nn.Linear(1000, 512)\n",
    "            self.fc3 = nn.Linear(512, 256)\n",
    "            self.fc4 = nn.Linear(256, 128)\n",
    "            self.fc5 = nn.Linear(128, 2)  # Output two values for regression\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = torch.relu(self.fc3(x))\n",
    "            x = torch.relu(self.fc4(x))\n",
    "            x = self.fc5(x)  # Linear output layer for regression\n",
    "            return x\n",
    "\n",
    "    # class TimeSeriesRegressor(nn.Module):\n",
    "    #     def __init__(self):\n",
    "    #         super(TimeSeriesRegressor, self).__init__()\n",
    "    #         self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "    #         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    #         self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    #         self.fc = nn.Linear(64 * 1416, 2)  # Output two values for regression\n",
    "\n",
    "    #     def forward(self, x):\n",
    "    #         x = x.unsqueeze(1)\n",
    "    #         # Assuming input shape is (batch_size, seq_length, input_size)\n",
    "    #         # Reshape input to (batch_size, input_size, seq_length)\n",
    "    #         # x = x.permute(0, 2, 1)\n",
    "    #         x = x.permute(0, 1, 2)\n",
    "\n",
    "            \n",
    "    #         x = F.relu(self.conv1(x))\n",
    "    #         x = F.relu(self.conv2(x))\n",
    "    #         x = F.relu(self.conv3(x))\n",
    "\n",
    "    #         # Flatten the output for fully connected layer\n",
    "    #         x = x.view(x.size(0), -1)\n",
    "    #         x = self.fc(x)  # Linear output layer for regression\n",
    "    #         return x\n",
    "\n",
    "    # Instantiate your model\n",
    "    model = TimeSeriesRegressor()\n",
    "\n",
    "    # Check if GPU is available and move the model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Define your loss function and optimizer\n",
    "    # criterion = nn.MSELoss()\n",
    "    criterion = nn.HuberLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Create a SummaryWriter for TensorBoard\n",
    "    writer = SummaryWriter()\n",
    "    best_metric = float('inf')\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "\n",
    "        if val_loss < best_metric:\n",
    "            best_metric = val_loss\n",
    "            torch.save(model.state_dict(), '../participant_wise_models/deep_learning_models/best_model{}.pth'.format(subject_number))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Subject number:  0\n",
      "Epoch 1/100, Train Loss: 5.7787, Val Loss: 1.8023\n",
      "Epoch 2/100, Train Loss: 1.8500, Val Loss: 1.8593\n",
      "Epoch 3/100, Train Loss: 1.8865, Val Loss: 1.8326\n",
      "Epoch 4/100, Train Loss: 1.8464, Val Loss: 1.8918\n",
      "Epoch 5/100, Train Loss: 1.8909, Val Loss: 1.8205\n",
      "Epoch 6/100, Train Loss: 1.9497, Val Loss: 2.0290\n",
      "Epoch 7/100, Train Loss: 1.8453, Val Loss: 1.8381\n",
      "Epoch 8/100, Train Loss: 1.8187, Val Loss: 2.0166\n",
      "Epoch 9/100, Train Loss: 1.7968, Val Loss: 1.7618\n",
      "Epoch 10/100, Train Loss: 1.8247, Val Loss: 1.7519\n",
      "Epoch 11/100, Train Loss: 1.8203, Val Loss: 1.8466\n",
      "Epoch 12/100, Train Loss: 1.8061, Val Loss: 1.7934\n",
      "Epoch 13/100, Train Loss: 1.8344, Val Loss: 1.7434\n",
      "Epoch 14/100, Train Loss: 1.8136, Val Loss: 1.7384\n",
      "Epoch 15/100, Train Loss: 1.8694, Val Loss: 1.7568\n",
      "Epoch 16/100, Train Loss: 1.8668, Val Loss: 1.7367\n",
      "Epoch 17/100, Train Loss: 1.7931, Val Loss: 1.7631\n",
      "Epoch 18/100, Train Loss: 1.8335, Val Loss: 1.7327\n",
      "Epoch 19/100, Train Loss: 1.7754, Val Loss: 1.7401\n",
      "Epoch 20/100, Train Loss: 1.8035, Val Loss: 1.7363\n",
      "Epoch 21/100, Train Loss: 1.8149, Val Loss: 1.8590\n",
      "Epoch 22/100, Train Loss: 1.8027, Val Loss: 1.9336\n",
      "Epoch 23/100, Train Loss: 1.8109, Val Loss: 1.7515\n",
      "Epoch 24/100, Train Loss: 1.7772, Val Loss: 1.7339\n",
      "Epoch 25/100, Train Loss: 1.7849, Val Loss: 1.7541\n",
      "Epoch 26/100, Train Loss: 1.7981, Val Loss: 1.9656\n",
      "Epoch 27/100, Train Loss: 1.8805, Val Loss: 2.0252\n",
      "Epoch 28/100, Train Loss: 1.8039, Val Loss: 1.7583\n",
      "Epoch 29/100, Train Loss: 1.7895, Val Loss: 1.8110\n",
      "Epoch 30/100, Train Loss: 1.7955, Val Loss: 1.7509\n",
      "Epoch 31/100, Train Loss: 1.8127, Val Loss: 1.7384\n",
      "Epoch 32/100, Train Loss: 1.7665, Val Loss: 1.7428\n",
      "Epoch 33/100, Train Loss: 1.8143, Val Loss: 1.7475\n",
      "Epoch 34/100, Train Loss: 1.7842, Val Loss: 1.7467\n",
      "Epoch 35/100, Train Loss: 1.7976, Val Loss: 1.7716\n",
      "Epoch 36/100, Train Loss: 1.8078, Val Loss: 1.7327\n",
      "Epoch 37/100, Train Loss: 1.7789, Val Loss: 1.7386\n",
      "Epoch 38/100, Train Loss: 1.7986, Val Loss: 1.7776\n",
      "Epoch 39/100, Train Loss: 1.7742, Val Loss: 1.7290\n",
      "Epoch 40/100, Train Loss: 1.8118, Val Loss: 1.8372\n",
      "Epoch 41/100, Train Loss: 1.8247, Val Loss: 1.7240\n",
      "Epoch 42/100, Train Loss: 1.7669, Val Loss: 1.7228\n",
      "Epoch 43/100, Train Loss: 1.7659, Val Loss: 1.7477\n",
      "Epoch 44/100, Train Loss: 1.7742, Val Loss: 1.7424\n",
      "Epoch 45/100, Train Loss: 1.8128, Val Loss: 1.7617\n",
      "Epoch 46/100, Train Loss: 1.7696, Val Loss: 1.8129\n",
      "Epoch 47/100, Train Loss: 1.7836, Val Loss: 1.7953\n",
      "Epoch 48/100, Train Loss: 1.7679, Val Loss: 1.7441\n",
      "Epoch 49/100, Train Loss: 1.8277, Val Loss: 1.7841\n",
      "Epoch 50/100, Train Loss: 1.7730, Val Loss: 1.7917\n",
      "Epoch 51/100, Train Loss: 1.8208, Val Loss: 1.7215\n",
      "Epoch 52/100, Train Loss: 1.7576, Val Loss: 1.7628\n",
      "Epoch 53/100, Train Loss: 1.7987, Val Loss: 1.7310\n",
      "Epoch 54/100, Train Loss: 1.7513, Val Loss: 1.7186\n",
      "Epoch 55/100, Train Loss: 1.7620, Val Loss: 1.7753\n",
      "Epoch 56/100, Train Loss: 1.7782, Val Loss: 1.8999\n",
      "Epoch 57/100, Train Loss: 1.8006, Val Loss: 1.7298\n",
      "Epoch 58/100, Train Loss: 1.7926, Val Loss: 1.8015\n",
      "Epoch 59/100, Train Loss: 1.7937, Val Loss: 1.7359\n",
      "Epoch 60/100, Train Loss: 1.7578, Val Loss: 1.7263\n",
      "Epoch 61/100, Train Loss: 1.7533, Val Loss: 1.7201\n",
      "Epoch 62/100, Train Loss: 1.7625, Val Loss: 1.7178\n",
      "Epoch 63/100, Train Loss: 1.7717, Val Loss: 1.7194\n",
      "Epoch 64/100, Train Loss: 1.7440, Val Loss: 1.7597\n",
      "Epoch 65/100, Train Loss: 1.8229, Val Loss: 1.7207\n",
      "Epoch 66/100, Train Loss: 1.7565, Val Loss: 1.7173\n",
      "Epoch 67/100, Train Loss: 1.7494, Val Loss: 1.7215\n",
      "Epoch 68/100, Train Loss: 1.7534, Val Loss: 1.7172\n",
      "Epoch 69/100, Train Loss: 1.7606, Val Loss: 1.8293\n",
      "Epoch 70/100, Train Loss: 1.7654, Val Loss: 1.7290\n",
      "Epoch 71/100, Train Loss: 1.7731, Val Loss: 1.7423\n",
      "Epoch 72/100, Train Loss: 1.7439, Val Loss: 1.7094\n",
      "Epoch 73/100, Train Loss: 1.7949, Val Loss: 1.8479\n",
      "Epoch 74/100, Train Loss: 1.7761, Val Loss: 1.7142\n",
      "Epoch 75/100, Train Loss: 1.7520, Val Loss: 1.7620\n",
      "Epoch 76/100, Train Loss: 1.7441, Val Loss: 1.7548\n",
      "Epoch 77/100, Train Loss: 1.7593, Val Loss: 1.7347\n",
      "Epoch 78/100, Train Loss: 1.7419, Val Loss: 1.7589\n",
      "Epoch 79/100, Train Loss: 1.8808, Val Loss: 1.7178\n",
      "Epoch 80/100, Train Loss: 1.7488, Val Loss: 1.7157\n",
      "Epoch 81/100, Train Loss: 1.7402, Val Loss: 1.7198\n",
      "Epoch 82/100, Train Loss: 1.7350, Val Loss: 1.7568\n",
      "Epoch 83/100, Train Loss: 1.7469, Val Loss: 1.7259\n",
      "Epoch 84/100, Train Loss: 1.7351, Val Loss: 1.7268\n",
      "Epoch 85/100, Train Loss: 1.7460, Val Loss: 1.8905\n",
      "Epoch 86/100, Train Loss: 1.7448, Val Loss: 1.7006\n",
      "Epoch 87/100, Train Loss: 1.7403, Val Loss: 1.7005\n",
      "Epoch 88/100, Train Loss: 1.7651, Val Loss: 1.6981\n",
      "Epoch 89/100, Train Loss: 1.7289, Val Loss: 1.8725\n",
      "Epoch 90/100, Train Loss: 1.7583, Val Loss: 1.6968\n",
      "Epoch 91/100, Train Loss: 1.7471, Val Loss: 1.7080\n",
      "Epoch 92/100, Train Loss: 1.7669, Val Loss: 1.7984\n",
      "Epoch 93/100, Train Loss: 1.7625, Val Loss: 1.7090\n",
      "Epoch 94/100, Train Loss: 1.7161, Val Loss: 1.6949\n",
      "Epoch 95/100, Train Loss: 1.7731, Val Loss: 1.7639\n",
      "Epoch 96/100, Train Loss: 1.7214, Val Loss: 1.9038\n",
      "Epoch 97/100, Train Loss: 1.7957, Val Loss: 1.7024\n",
      "Epoch 98/100, Train Loss: 1.7429, Val Loss: 1.6953\n",
      "Epoch 99/100, Train Loss: 1.7344, Val Loss: 1.6959\n",
      "Epoch 100/100, Train Loss: 1.7275, Val Loss: 1.6866\n",
      "Training for Subject number:  1\n",
      "Epoch 1/100, Train Loss: 3.9925, Val Loss: 1.8367\n",
      "Epoch 2/100, Train Loss: 1.9281, Val Loss: 1.7706\n",
      "Epoch 3/100, Train Loss: 1.9013, Val Loss: 1.8830\n",
      "Epoch 4/100, Train Loss: 1.8404, Val Loss: 1.9793\n",
      "Epoch 5/100, Train Loss: 1.8941, Val Loss: 1.8028\n",
      "Epoch 6/100, Train Loss: 1.8236, Val Loss: 1.8038\n",
      "Epoch 7/100, Train Loss: 1.7713, Val Loss: 1.8052\n",
      "Epoch 8/100, Train Loss: 1.8007, Val Loss: 1.8256\n",
      "Epoch 9/100, Train Loss: 1.8625, Val Loss: 1.9969\n",
      "Epoch 10/100, Train Loss: 1.8706, Val Loss: 1.7644\n",
      "Epoch 11/100, Train Loss: 1.8377, Val Loss: 1.7947\n",
      "Epoch 12/100, Train Loss: 1.8290, Val Loss: 1.8484\n",
      "Epoch 13/100, Train Loss: 1.8164, Val Loss: 1.8053\n",
      "Epoch 14/100, Train Loss: 1.7894, Val Loss: 1.8939\n",
      "Epoch 15/100, Train Loss: 1.8847, Val Loss: 1.9541\n",
      "Epoch 16/100, Train Loss: 1.8369, Val Loss: 1.9159\n",
      "Epoch 17/100, Train Loss: 1.7965, Val Loss: 1.7862\n",
      "Epoch 18/100, Train Loss: 1.8002, Val Loss: 1.8333\n",
      "Epoch 19/100, Train Loss: 1.8152, Val Loss: 1.7646\n",
      "Epoch 20/100, Train Loss: 1.8235, Val Loss: 1.7946\n",
      "Epoch 21/100, Train Loss: 1.8416, Val Loss: 1.7708\n",
      "Epoch 22/100, Train Loss: 1.8042, Val Loss: 1.7644\n",
      "Epoch 23/100, Train Loss: 1.8064, Val Loss: 1.7691\n",
      "Epoch 24/100, Train Loss: 1.7770, Val Loss: 1.8032\n",
      "Epoch 25/100, Train Loss: 1.7980, Val Loss: 1.7836\n",
      "Epoch 26/100, Train Loss: 1.7964, Val Loss: 1.8460\n",
      "Epoch 27/100, Train Loss: 1.7770, Val Loss: 1.7630\n",
      "Epoch 28/100, Train Loss: 1.7711, Val Loss: 1.8056\n",
      "Epoch 29/100, Train Loss: 1.7833, Val Loss: 1.7833\n",
      "Epoch 30/100, Train Loss: 1.7761, Val Loss: 1.7817\n",
      "Epoch 31/100, Train Loss: 1.8029, Val Loss: 1.9693\n",
      "Epoch 32/100, Train Loss: 1.8507, Val Loss: 1.7912\n",
      "Epoch 33/100, Train Loss: 1.8191, Val Loss: 1.8133\n",
      "Epoch 34/100, Train Loss: 1.7805, Val Loss: 1.8771\n",
      "Epoch 35/100, Train Loss: 1.8058, Val Loss: 1.8354\n",
      "Epoch 36/100, Train Loss: 1.8210, Val Loss: 1.8336\n",
      "Epoch 37/100, Train Loss: 1.8075, Val Loss: 1.7952\n",
      "Epoch 38/100, Train Loss: 1.7655, Val Loss: 1.7663\n",
      "Epoch 39/100, Train Loss: 1.7594, Val Loss: 1.8060\n",
      "Epoch 40/100, Train Loss: 1.7653, Val Loss: 1.7637\n",
      "Epoch 41/100, Train Loss: 1.7684, Val Loss: 1.8146\n",
      "Epoch 42/100, Train Loss: 1.8077, Val Loss: 1.7685\n",
      "Epoch 43/100, Train Loss: 1.7610, Val Loss: 1.8094\n",
      "Epoch 44/100, Train Loss: 1.7895, Val Loss: 1.8831\n",
      "Epoch 45/100, Train Loss: 1.7978, Val Loss: 1.7987\n",
      "Epoch 46/100, Train Loss: 1.8101, Val Loss: 1.8150\n",
      "Epoch 47/100, Train Loss: 1.7973, Val Loss: 1.7792\n",
      "Epoch 48/100, Train Loss: 1.8033, Val Loss: 1.8685\n",
      "Epoch 49/100, Train Loss: 1.7811, Val Loss: 1.8043\n",
      "Epoch 50/100, Train Loss: 1.7890, Val Loss: 1.7811\n",
      "Epoch 51/100, Train Loss: 1.8106, Val Loss: 1.7962\n",
      "Epoch 52/100, Train Loss: 1.7993, Val Loss: 1.7660\n",
      "Epoch 53/100, Train Loss: 1.7717, Val Loss: 1.7700\n",
      "Epoch 54/100, Train Loss: 1.7716, Val Loss: 1.7820\n",
      "Epoch 55/100, Train Loss: 1.8024, Val Loss: 1.7842\n",
      "Epoch 56/100, Train Loss: 1.8091, Val Loss: 1.7829\n",
      "Epoch 57/100, Train Loss: 1.7691, Val Loss: 1.8046\n",
      "Epoch 58/100, Train Loss: 1.7621, Val Loss: 1.7644\n",
      "Epoch 59/100, Train Loss: 1.7613, Val Loss: 1.7780\n",
      "Epoch 60/100, Train Loss: 1.7701, Val Loss: 1.7910\n",
      "Epoch 61/100, Train Loss: 1.7786, Val Loss: 1.7646\n",
      "Epoch 62/100, Train Loss: 1.7705, Val Loss: 1.8291\n",
      "Epoch 63/100, Train Loss: 1.8069, Val Loss: 1.9018\n",
      "Epoch 64/100, Train Loss: 1.8231, Val Loss: 1.8809\n",
      "Epoch 65/100, Train Loss: 1.8002, Val Loss: 1.8103\n",
      "Epoch 66/100, Train Loss: 1.7909, Val Loss: 1.7904\n",
      "Epoch 67/100, Train Loss: 1.7709, Val Loss: 1.7718\n",
      "Epoch 68/100, Train Loss: 1.7643, Val Loss: 1.7712\n",
      "Epoch 69/100, Train Loss: 1.8003, Val Loss: 1.7607\n",
      "Epoch 70/100, Train Loss: 1.7643, Val Loss: 1.8190\n",
      "Epoch 71/100, Train Loss: 1.7656, Val Loss: 1.7700\n",
      "Epoch 72/100, Train Loss: 1.7630, Val Loss: 1.7752\n",
      "Epoch 73/100, Train Loss: 1.7731, Val Loss: 1.8039\n",
      "Epoch 74/100, Train Loss: 1.8186, Val Loss: 1.8582\n",
      "Epoch 75/100, Train Loss: 1.7857, Val Loss: 1.7694\n",
      "Epoch 76/100, Train Loss: 1.7667, Val Loss: 1.7841\n",
      "Epoch 77/100, Train Loss: 1.7668, Val Loss: 1.7685\n",
      "Epoch 78/100, Train Loss: 1.7782, Val Loss: 1.7818\n",
      "Epoch 79/100, Train Loss: 1.7769, Val Loss: 1.7605\n",
      "Epoch 80/100, Train Loss: 1.7802, Val Loss: 1.7906\n",
      "Epoch 81/100, Train Loss: 1.7597, Val Loss: 1.7661\n",
      "Epoch 82/100, Train Loss: 1.7837, Val Loss: 1.7676\n",
      "Epoch 83/100, Train Loss: 1.7509, Val Loss: 1.8269\n",
      "Epoch 84/100, Train Loss: 1.7577, Val Loss: 1.7705\n",
      "Epoch 85/100, Train Loss: 1.7842, Val Loss: 1.7786\n",
      "Epoch 86/100, Train Loss: 1.7865, Val Loss: 1.7680\n",
      "Epoch 87/100, Train Loss: 1.7693, Val Loss: 1.7690\n",
      "Epoch 88/100, Train Loss: 1.7815, Val Loss: 1.7751\n",
      "Epoch 89/100, Train Loss: 1.8057, Val Loss: 1.8509\n",
      "Epoch 90/100, Train Loss: 1.7670, Val Loss: 1.8850\n",
      "Epoch 91/100, Train Loss: 1.7932, Val Loss: 1.7604\n",
      "Epoch 92/100, Train Loss: 1.7646, Val Loss: 1.8053\n",
      "Epoch 93/100, Train Loss: 1.7831, Val Loss: 1.7795\n",
      "Epoch 94/100, Train Loss: 1.7667, Val Loss: 1.7618\n",
      "Epoch 95/100, Train Loss: 1.7783, Val Loss: 1.7810\n",
      "Epoch 96/100, Train Loss: 1.7639, Val Loss: 1.7839\n",
      "Epoch 97/100, Train Loss: 1.7823, Val Loss: 1.7665\n",
      "Epoch 98/100, Train Loss: 1.7824, Val Loss: 1.8237\n",
      "Epoch 99/100, Train Loss: 1.8017, Val Loss: 1.8008\n",
      "Epoch 100/100, Train Loss: 1.7779, Val Loss: 1.7683\n",
      "Training for Subject number:  2\n",
      "Epoch 1/100, Train Loss: 6.2094, Val Loss: 1.9599\n",
      "Epoch 2/100, Train Loss: 1.8917, Val Loss: 1.7526\n",
      "Epoch 3/100, Train Loss: 1.8489, Val Loss: 1.9079\n",
      "Epoch 4/100, Train Loss: 1.8151, Val Loss: 1.8111\n",
      "Epoch 5/100, Train Loss: 1.8032, Val Loss: 1.7667\n",
      "Epoch 6/100, Train Loss: 1.8194, Val Loss: 1.8960\n",
      "Epoch 7/100, Train Loss: 1.8597, Val Loss: 1.7445\n",
      "Epoch 8/100, Train Loss: 1.8612, Val Loss: 1.9816\n",
      "Epoch 9/100, Train Loss: 1.9392, Val Loss: 1.7812\n",
      "Epoch 10/100, Train Loss: 1.8098, Val Loss: 1.7611\n",
      "Epoch 11/100, Train Loss: 1.8531, Val Loss: 1.9441\n",
      "Epoch 12/100, Train Loss: 1.8570, Val Loss: 2.1055\n",
      "Epoch 13/100, Train Loss: 1.9139, Val Loss: 1.7646\n",
      "Epoch 14/100, Train Loss: 1.8098, Val Loss: 1.7417\n",
      "Epoch 15/100, Train Loss: 1.7811, Val Loss: 1.7705\n",
      "Epoch 16/100, Train Loss: 1.7681, Val Loss: 1.8021\n",
      "Epoch 17/100, Train Loss: 1.8929, Val Loss: 1.7618\n",
      "Epoch 18/100, Train Loss: 1.8106, Val Loss: 1.7354\n",
      "Epoch 19/100, Train Loss: 1.8077, Val Loss: 1.7285\n",
      "Epoch 20/100, Train Loss: 1.7757, Val Loss: 1.8422\n",
      "Epoch 21/100, Train Loss: 1.8178, Val Loss: 1.8523\n",
      "Epoch 22/100, Train Loss: 1.8219, Val Loss: 1.7996\n",
      "Epoch 23/100, Train Loss: 1.8100, Val Loss: 1.7670\n",
      "Epoch 24/100, Train Loss: 1.7796, Val Loss: 1.7520\n",
      "Epoch 25/100, Train Loss: 1.7622, Val Loss: 1.7326\n",
      "Epoch 26/100, Train Loss: 1.8545, Val Loss: 1.7412\n",
      "Epoch 27/100, Train Loss: 1.7994, Val Loss: 1.7549\n",
      "Epoch 28/100, Train Loss: 1.8104, Val Loss: 1.8199\n",
      "Epoch 29/100, Train Loss: 1.8139, Val Loss: 1.7532\n",
      "Epoch 30/100, Train Loss: 1.7852, Val Loss: 1.7577\n",
      "Epoch 31/100, Train Loss: 1.7952, Val Loss: 1.7891\n",
      "Epoch 32/100, Train Loss: 1.8167, Val Loss: 1.7817\n",
      "Epoch 33/100, Train Loss: 1.8151, Val Loss: 1.7502\n",
      "Epoch 34/100, Train Loss: 1.7752, Val Loss: 1.7768\n",
      "Epoch 35/100, Train Loss: 1.8105, Val Loss: 1.8149\n",
      "Epoch 36/100, Train Loss: 1.7977, Val Loss: 1.7474\n",
      "Epoch 37/100, Train Loss: 1.7904, Val Loss: 1.7535\n",
      "Epoch 38/100, Train Loss: 1.7760, Val Loss: 1.7499\n",
      "Epoch 39/100, Train Loss: 1.8047, Val Loss: 1.7675\n",
      "Epoch 40/100, Train Loss: 1.7876, Val Loss: 1.7363\n",
      "Epoch 41/100, Train Loss: 1.7763, Val Loss: 1.7335\n",
      "Epoch 42/100, Train Loss: 1.8356, Val Loss: 1.9081\n",
      "Epoch 43/100, Train Loss: 1.8603, Val Loss: 1.8713\n",
      "Epoch 44/100, Train Loss: 1.7741, Val Loss: 1.7743\n",
      "Epoch 45/100, Train Loss: 1.8461, Val Loss: 1.7329\n",
      "Epoch 46/100, Train Loss: 1.7819, Val Loss: 1.7350\n",
      "Epoch 47/100, Train Loss: 1.8124, Val Loss: 1.8130\n",
      "Epoch 48/100, Train Loss: 1.7866, Val Loss: 1.7321\n",
      "Epoch 49/100, Train Loss: 1.7845, Val Loss: 1.8496\n",
      "Epoch 50/100, Train Loss: 1.7889, Val Loss: 1.7412\n",
      "Epoch 51/100, Train Loss: 1.7894, Val Loss: 1.7382\n",
      "Epoch 52/100, Train Loss: 1.7691, Val Loss: 1.7305\n",
      "Epoch 53/100, Train Loss: 1.7935, Val Loss: 1.8199\n",
      "Epoch 54/100, Train Loss: 1.7727, Val Loss: 1.7317\n",
      "Epoch 55/100, Train Loss: 1.7579, Val Loss: 1.7520\n",
      "Epoch 56/100, Train Loss: 1.8350, Val Loss: 1.7362\n",
      "Epoch 57/100, Train Loss: 1.7707, Val Loss: 1.7516\n",
      "Epoch 58/100, Train Loss: 1.8097, Val Loss: 1.7449\n",
      "Epoch 59/100, Train Loss: 1.7682, Val Loss: 1.7409\n",
      "Epoch 60/100, Train Loss: 1.7740, Val Loss: 1.7277\n",
      "Epoch 61/100, Train Loss: 1.7683, Val Loss: 1.7669\n",
      "Epoch 62/100, Train Loss: 1.7859, Val Loss: 1.7391\n",
      "Epoch 63/100, Train Loss: 1.7847, Val Loss: 1.7979\n",
      "Epoch 64/100, Train Loss: 1.7966, Val Loss: 1.7506\n",
      "Epoch 65/100, Train Loss: 1.7689, Val Loss: 1.7643\n",
      "Epoch 66/100, Train Loss: 1.7858, Val Loss: 1.7452\n",
      "Epoch 67/100, Train Loss: 1.7785, Val Loss: 1.7535\n",
      "Epoch 68/100, Train Loss: 1.7829, Val Loss: 1.8536\n",
      "Epoch 69/100, Train Loss: 1.8078, Val Loss: 1.7423\n",
      "Epoch 70/100, Train Loss: 1.7813, Val Loss: 1.7423\n",
      "Epoch 71/100, Train Loss: 1.8843, Val Loss: 1.7529\n",
      "Epoch 72/100, Train Loss: 1.7576, Val Loss: 1.7325\n",
      "Epoch 73/100, Train Loss: 1.7718, Val Loss: 1.7475\n",
      "Epoch 74/100, Train Loss: 1.7936, Val Loss: 1.8797\n",
      "Epoch 75/100, Train Loss: 1.8011, Val Loss: 1.8302\n",
      "Epoch 76/100, Train Loss: 1.7939, Val Loss: 1.7552\n",
      "Epoch 77/100, Train Loss: 1.7812, Val Loss: 1.7288\n",
      "Epoch 78/100, Train Loss: 1.7647, Val Loss: 1.7370\n",
      "Epoch 79/100, Train Loss: 1.7660, Val Loss: 1.8000\n",
      "Epoch 80/100, Train Loss: 1.7756, Val Loss: 1.7301\n",
      "Epoch 81/100, Train Loss: 1.7756, Val Loss: 1.7864\n",
      "Epoch 82/100, Train Loss: 1.7838, Val Loss: 1.7300\n",
      "Epoch 83/100, Train Loss: 1.7922, Val Loss: 1.7275\n",
      "Epoch 84/100, Train Loss: 1.7780, Val Loss: 1.8802\n",
      "Epoch 85/100, Train Loss: 1.8083, Val Loss: 1.7428\n",
      "Epoch 86/100, Train Loss: 1.8070, Val Loss: 1.7530\n",
      "Epoch 87/100, Train Loss: 1.7671, Val Loss: 1.7414\n",
      "Epoch 88/100, Train Loss: 1.7976, Val Loss: 1.7563\n",
      "Epoch 89/100, Train Loss: 1.7709, Val Loss: 1.7324\n",
      "Epoch 90/100, Train Loss: 1.7845, Val Loss: 1.7568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 99\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(X_train, y_train, X_test, y_test, subject_number)\u001b[0m\n\u001b[1;32m     97\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     98\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 99\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    101\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/DATAHDD/chailex/anaconda3/envs/eeg/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/DATAHDD/chailex/anaconda3/envs/eeg/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dd in range(3):\n",
    "    original_data = pd.read_csv(\"../participant_wise_data/participant_{}_data.csv\".format(dd))\n",
    "    data = list()\n",
    "    for i in range(len(original_data)):\n",
    "        temp = list()\n",
    "        temp.append(original_data.iloc[i,0])\n",
    "        temp.append(original_data.iloc[i,1])\n",
    "        list_data = ast.literal_eval(original_data.iloc[i,2])\n",
    "        temp.append(list_data)\n",
    "        temp.append(ast.literal_eval(original_data.iloc[i,3]))\n",
    "        data.append(temp)\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df.iloc[:,2]\n",
    "    y = df.iloc[:,3]\n",
    "\n",
    "    time_series_data = X\n",
    "    targets = y\n",
    "\n",
    "    data = pd.DataFrame({'time_series_data': time_series_data, 'target': targets})\n",
    "\n",
    "    X = np.array(data['time_series_data'].tolist())\n",
    "    y = np.array(data['target'].tolist())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    training(X_train, y_train, X_test, y_test, dd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATAHDD/chailex/anaconda3/envs/eeg/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7557017285421709\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "[2.53848039 3.17584351]\n",
      "-0.7557017285421709\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATAHDD/chailex/anaconda3/envs/eeg/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7976107616862543\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "[2.50078139 3.07218154]\n",
      "-0.7976107616862543\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAGdCAYAAAAc+wceAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwo0lEQVR4nO3de3SU1b3/8c+EkCEXZsItM4QEG4sFAqFysTBF7bKmRBprLaiFpoiKWmhQAxYpS0VrVVjYHg+eFtDan2GtIyqcU63cT8q1QuQSDQYCESs1SJxgxcwAQghk//6gecwkISQhmUmY92utZy3n2d888322yHzcM3tiM8YYAQAAhLmIUDcAAADQHhCKAAAARCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQJEWGuoG2Ul1drbKyMnXt2lU2my3U7QAAgCYwxuj48eNKTExURERw124u21BUVlam5OTkULcBAABa4PDhw0pKSgrqc162oahr166Szk+qw+EIcTcAAKAp/H6/kpOTrdfxYLpsQ1HNW2YOh4NQBABABxOKj77wQWsAAAARigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACRdxt9ojZbpe490+F9fP07uKZX+v9D1AwAdjd/llPz+r084HHKU+0LXEJqMlSJYbLcEBiLp/GPbLaHpBwA6Gn+0LTAQSZLff/482j1CESSdXyFqTMqU4PQBAB2V3+VsfNzdLUidoKUIRZBUf4Worn9+Hpw+AKDDqrtCVJevIihtoOUIRQAAACIUAQAASCIU4d+SezY+/o1ewekDADosh6PxcWd8UNpAyxGKIOni2+4P/Tk4fQBAR3WxbfcO75dB6gQtRSiCxbxdf0XoG73OnwcAXJzjlKm/IuSMP38e7R5f3ogArAgBwKVhRajjYqUIAABAhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJLQhFR44c0c9//nP16NFD0dHRSktL0+7du61xY4zmzp2r3r17Kzo6Wunp6Tp48GDANY4dO6asrCw5HA7Fx8drypQpOnHiREDNBx98oOuuu05dunRRcnKyFixY0MJbBAAAuLhmhaIvv/xSo0ePVufOnbV27VoVFxfr97//vbp162bVLFiwQC+88IKWLFmiHTt2KDY2VhkZGTp9+rRVk5WVpX379ikvL0+rVq3S1q1bdf/991vjfr9fY8aM0RVXXKGCggI999xzevLJJ/XSSy+1wi0DAADUZzPGmKYW//rXv9a2bdv097//vcFxY4wSExP18MMP61e/+pUkyefzyeVyKTc3VxMmTND+/fuVmpqqXbt2acSIEZKkdevW6Yc//KE+/fRTJSYmavHixXr00Ufl9XoVFRVlPfdbb72lAwcONKlXv98vp9Mpn88nh8PR1FsEAAAhFMrX72atFL399tsaMWKEbr/9diUkJGjo0KH605/+ZI0fOnRIXq9X6enp1jmn06mRI0cqPz9fkpSfn6/4+HgrEElSenq6IiIitGPHDqvm+uuvtwKRJGVkZKikpERffvllg71VVlbK7/cHHAAAAE3VrFD08ccfa/Hixbrqqqu0fv16TZs2TQ8++KCWLl0qSfJ6vZIkl8sV8HMul8sa83q9SkhICBiPjIxU9+7dA2oaukbt56hr3rx5cjqd1pGcnNycWwMAAGGuWaGourpaw4YN07PPPquhQ4fq/vvv13333aclS5a0VX9NNmfOHPl8Pus4fPhwqFsCAAAdSLNCUe/evZWamhpwbuDAgSotLZUkud1uSVJ5eXlATXl5uTXmdrt19OjRgPGzZ8/q2LFjATUNXaP2c9Rlt9vlcDgCDgAAgKZqVigaPXq0SkpKAs59+OGHuuKKKyRJKSkpcrvd2rBhgzXu9/u1Y8cOeTweSZLH41FFRYUKCgqsmo0bN6q6ulojR460arZu3aqqqiqrJi8vT/379w/Y6QYAANBamhWKZsyYoXfffVfPPvusPvroIy1btkwvvfSSsrOzJUk2m005OTl6+umn9fbbb6uoqEh33nmnEhMTdeutt0o6v7J000036b777tPOnTu1bds2TZ8+XRMmTFBiYqIk6Wc/+5mioqI0ZcoU7du3T2+88YYWLlyomTNntu7dAwAA1DDNtHLlSjN48GBjt9vNgAEDzEsvvRQwXl1dbR5//HHjcrmM3W43N954oykpKQmo+eKLL8zEiRNNXFyccTgc5u677zbHjx8PqNmzZ4+59tprjd1uN3369DHz589vVp8+n89IMj6fr7m3CAAAQiSUr9/N+p6ijoTvKQIAoOPpMN9TBAAAcLkiFAEAAIhQBAAAIEmKDHUDHcm6uDiZkyetx7bYWN104kQIOwLCzy/0F32hU9bjHorWixoXwo6A8PK73r11stZvl4h1u/Wrzz4LYUeth5WiJlprswUEIkkyJ09qrc0Woo6A8HObXg0IRJL0hU7pNr0aoo6A8PIbmy0gEEnSSa9Xv7lMXgsJRU2wLi6u0fH17G4D2twv9JdGx6fpzSB1AoSn3/Xu3ej475OSgtRJ2yEUNUHdFaK6qo8fD1InQPiqu0JU1+f6KkidAOGp7gpRXSeOHAlSJ22HUAQAACBCEQAAgCRCUZPYYmMbHY/o2jVInQDhq4eiGx3vpZggdQKEp1i3u9HxuD59gtRJ2yEUNcHFtt1n+P1B6gQIXxfbdr9YPwlSJ0B4uti2+4c//TRInbQdQlETjTWm3opQRNeuGnt5/uo4oF36H2XVWxHqpRj9j7JC1BEQXp4wpt6KUFyfPnriMnkt5BfCAgCAdoNfCAsAABBihCIAAAARigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACQRigAAACRJkaFuAEDrGa9i7Vel9Xig7PpfpYawIzRXXFmlTtZ6HCvpRKI9VO0AYYWVIuAykar3AwKRJO1XpVL1fog6QnPZ6gQiSTr57/MA2h6hCLgMjFdxo+N3aH+QOkFLxV0k+DgIRkCba1YoevLJJ2Wz2QKOAQMGWOOnT59Wdna2evToobi4OI0fP17l5eUB1ygtLVVmZqZiYmKUkJCgWbNm6ezZswE1mzdv1rBhw2S329WvXz/l5ua2/A6BMFB3haiuvTodpE7QUnVXiOo6HpQugPDW7JWiQYMG6bPPPrOOd955xxqbMWOGVq5cqRUrVmjLli0qKyvTuHHjrPFz584pMzNTZ86c0fbt27V06VLl5uZq7ty5Vs2hQ4eUmZmpG264QYWFhcrJydG9996r9evXX+KtAgAAXFizP2gdGRkpt9td77zP59Of//xnLVu2TN///vclSa+88ooGDhyod999V6NGjdL//d//qbi4WH/729/kcrl09dVX67e//a1mz56tJ598UlFRUVqyZIlSUlL0+9//XpI0cOBAvfPOO3r++eeVkZFxibcLAADQsGavFB08eFCJiYm68sorlZWVpdLSUklSQUGBqqqqlJ6ebtUOGDBAffv2VX5+viQpPz9faWlpcrlcVk1GRob8fr/27dtn1dS+Rk1NzTUupLKyUn6/P+AAwsVANb47abC6BKkTtFTsRca7BqULILw1KxSNHDlSubm5WrdunRYvXqxDhw7puuuu0/Hjx+X1ehUVFaX4+PiAn3G5XPJ6vZIkr9cbEIhqxmvGGqvx+/06derUBXubN2+enE6ndSQnJzfn1oAO7WLb7pdrYJA6QUtdbNu9n235QJtrVigaO3asbr/9dg0ZMkQZGRlas2aNKioqtHz58rbqr8nmzJkjn89nHYcPHw51S0BQFWtovRWhweqiYg0NUUdoLpNor7ci1PXf5wG0vUv68sb4+Hh961vf0kcffaQf/OAHOnPmjCoqKgJWi8rLy63PILndbu3cuTPgGjW702rX1N2xVl5eLofDoejo6Av2YrfbZbfzFwfCGytCHR8rQkDoXNL3FJ04cUL/+Mc/1Lt3bw0fPlydO3fWhg0brPGSkhKVlpbK4/FIkjwej4qKinT06FGrJi8vTw6HQ6mpqVZN7WvU1NRcAwAAoC00KxT96le/0pYtW/TPf/5T27dv109+8hN16tRJEydOlNPp1JQpUzRz5kxt2rRJBQUFuvvuu+XxeDRq1ChJ0pgxY5SamqpJkyZpz549Wr9+vR577DFlZ2dbqzxTp07Vxx9/rEceeUQHDhzQokWLtHz5cs2YMaP17x4AAODfmvX22aeffqqJEyfqiy++UK9evXTttdfq3XffVa9evSRJzz//vCIiIjR+/HhVVlYqIyNDixYtsn6+U6dOWrVqlaZNmyaPx6PY2FhNnjxZTz31lFWTkpKi1atXa8aMGVq4cKGSkpL08ssvsx0fAAC0KZsxxoS6ibbg9/vldDrl8/nkcDhC3Q4AAGiCUL5+87vPAAAARCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQRCgCAACQJEWGugEgmHqtkf519uvHPSOlz38Yun6AcDRokVT8r68fp/aU9v0ydP0ANVgpQtiwvR0YiKTzj21vh6YfIBzZngoMRNL5x7anQtMPUBuhCGGh15rGx91rg9MHEM4GLWp8fMji4PQBXAihCGGh7gpRXeVVwekDCGd1V4jqKvo8OH0AF0IoAgAAEKEIAABAEqEIYaLnRfZZujoHpw8gnKX2bHw8rVdw+gAuhFCEsHCxbffescHpAwhnF9t2/8G04PQBXAihCGHD3FJ/RcjV+fx5AMFh5tZfEUrrdf48EGp8eSPCCitCQOixIoT2ipUiAAAAEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkXWIomj9/vmw2m3Jycqxzp0+fVnZ2tnr06KG4uDiNHz9e5eXlAT9XWlqqzMxMxcTEKCEhQbNmzdLZs2cDajZv3qxhw4bJbrerX79+ys3NvZRWAQAAGtXiULRr1y69+OKLGjJkSMD5GTNmaOXKlVqxYoW2bNmisrIyjRs3zho/d+6cMjMzdebMGW3fvl1Lly5Vbm6u5s79+hffHDp0SJmZmbrhhhtUWFionJwc3XvvvVq/fn1L2wUAAGiUzRhjmvtDJ06c0LBhw7Ro0SI9/fTTuvrqq/Wf//mf8vl86tWrl5YtW6bbbrtNknTgwAENHDhQ+fn5GjVqlNauXaubb75ZZWVlcrlckqQlS5Zo9uzZ+vzzzxUVFaXZs2dr9erV2rt3r/WcEyZMUEVFhdatW9ekHv1+v5xOp3w+nxwOR3NvEQAAhEAoX79btFKUnZ2tzMxMpaenB5wvKChQVVVVwPkBAwaob9++ys/PlyTl5+crLS3NCkSSlJGRIb/fr3379lk1da+dkZFhXaMhlZWV8vv9AQcAAEBTRTb3B15//XW999572rVrV70xr9erqKgoxcfHB5x3uVzyer1WTe1AVDNeM9ZYjd/v16lTpxQdHV3vuefNm6ff/OY3zb0dAAAASc1cKTp8+LAeeughvfrqq+rSpUtb9dQic+bMkc/ns47Dhw+HuiUAANCBNCsUFRQU6OjRoxo2bJgiIyMVGRmpLVu26IUXXlBkZKRcLpfOnDmjioqKgJ8rLy+X2+2WJLnd7nq70WoeX6zG4XA0uEokSXa7XQ6HI+AAAABoqmaFohtvvFFFRUUqLCy0jhEjRigrK8v6586dO2vDhg3Wz5SUlKi0tFQej0eS5PF4VFRUpKNHj1o1eXl5cjgcSk1NtWpqX6OmpuYaAAAAra1Znynq2rWrBg8eHHAuNjZWPXr0sM5PmTJFM2fOVPfu3eVwOPTAAw/I4/Fo1KhRkqQxY8YoNTVVkyZN0oIFC+T1evXYY48pOztbdrtdkjR16lT94Q9/0COPPKJ77rlHGzdu1PLly7V69erWuGcAAIB6mv1B64t5/vnnFRERofHjx6uyslIZGRlatGiRNd6pUyetWrVK06ZNk8fjUWxsrCZPnqynnnrKqklJSdHq1as1Y8YMLVy4UElJSXr55ZeVkZHR2u0CAABIauH3FHUEfE8RAAAdT4f7niIAAIDLDaEIAABAhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJhCIAAABJUmSoG0A7c9dwqeS9rx/3HyblFoSuH6COeXpap3TKehytaM3RYyHsCAh07a3Stp1fPx79Hemdt0LVDZrDZowxoW6iLYTyt+x2WJ4ISQ39cbBJ+dXB7gaoZ64eveDYU3omiJ0ADeuUJFU38NdlRIR07tPg99MRhfL1m7fPcN5dw9VwINL58/d8J5jdAPXM09ONjs8nFCHErr214UAknT//vXFBbQctQCjCebXfMmvI/l3B6QO4gNpvmTXkK30VpE6AhtV+y6whW98NTh9oOUIRAACACEUAAACSCEWo0X9Y4+MDrwlOH8AFRCu60fEYxQSpE6Bhoy/y0cvrRwWnD7Qcu8/wNXafoZ1j9xnaO3afXTp2n6F9yK+uvyI08BoCEdqNp/RMvRWhGMUQiNBunPu0/orQ9aMIRB0FK0UAAKDdYKUIAAAgxAhFAAAAIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIIhQBAABIamYoWrx4sYYMGSKHwyGHwyGPx6O1a9da46dPn1Z2drZ69OihuLg4jR8/XuXl5QHXKC0tVWZmpmJiYpSQkKBZs2bp7NmzATWbN2/WsGHDZLfb1a9fP+Xm5rb8DgEAAJqgWaEoKSlJ8+fPV0FBgXbv3q3vf//7+vGPf6x9+/ZJkmbMmKGVK1dqxYoV2rJli8rKyjRu3Djr58+dO6fMzEydOXNG27dv19KlS5Wbm6u5c+daNYcOHVJmZqZuuOEGFRYWKicnR/fee6/Wr1/fSrcMAABQn80YYy7lAt27d9dzzz2n2267Tb169dKyZct02223SZIOHDiggQMHKj8/X6NGjdLatWt18803q6ysTC6XS5K0ZMkSzZ49W59//rmioqI0e/ZsrV69Wnv37rWeY8KECaqoqNC6deua3Jff75fT6ZTP55PD4biUWwQAAEESytfvFn+m6Ny5c3r99dd18uRJeTweFRQUqKqqSunp6VbNgAED1LdvX+Xn50uS8vPzlZaWZgUiScrIyJDf77dWm/Lz8wOuUVNTc40LqayslN/vDzgAAACaqtmhqKioSHFxcbLb7Zo6darefPNNpaamyuv1KioqSvHx8QH1LpdLXq9XkuT1egMCUc14zVhjNX6/X6dOnbpgX/PmzZPT6bSO5OTk5t4aAAAIY80ORf3791dhYaF27NihadOmafLkySouLm6L3pplzpw58vl81nH48OFQtwQAADqQyOb+QFRUlPr16ydJGj58uHbt2qWFCxfqpz/9qc6cOaOKioqA1aLy8nK53W5Jktvt1s6dOwOuV7M7rXZN3R1r5eXlcjgcio6OvmBfdrtddru9ubcDAAAgqRW+p6i6ulqVlZUaPny4OnfurA0bNlhjJSUlKi0tlcfjkSR5PB4VFRXp6NGjVk1eXp4cDodSU1OtmtrXqKmpuQZwSXL7Sn+0fX3k9g11R0D42T1I2mb7+tg9KNQdAZKauVI0Z84cjR07Vn379tXx48e1bNkybd68WevXr5fT6dSUKVM0c+ZMde/eXQ6HQw888IA8Ho9GjRolSRozZoxSU1M1adIkLViwQF6vV4899piys7OtVZ6pU6fqD3/4gx555BHdc8892rhxo5YvX67Vq1e3/t0jvPzRVv/cycPnz2df0iZMAE21rYH/DiuLz58fzX+HCK1mhaKjR4/qzjvv1GeffSan06khQ4Zo/fr1+sEPfiBJev755xUREaHx48ersrJSGRkZWrRokfXznTp10qpVqzRt2jR5PB7FxsZq8uTJeuqpp6yalJQUrV69WjNmzNDChQuVlJSkl19+WRkZGa10ywhLF1sRWpoiTT4UnF6AcHWxFaGCIdLwD4LTC9CAS/6eovaK7ylCgIZWiepitQhoWw2tEtXFalHY65DfUwQAAHA5IRQBAACIUIRwEXuRL/OM+0ZQ2gDCmj218fEuacHpA7gAQhHCw12ljY/zIWug7Y3Y1/g4H7JGiBGKED6yTf0Vobhv8AFrIJhGm/orQl3S+IA12oVmf6M10KGxIgSEHitCaKdYKQIAABChCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQJIUGeoGEN7uevQWPZT4sZIPHNHhAX20sOxK5T7zdqjb6rAqv+os6WytM5Gyx1SFqh20QLHGq1L7rcd2DVSq/jeEHQHhg1CEkHoo8WNd/eo+2YzUo6BCD2WFuqOOq/IrWwNnz6ryK5vsMSbo/aD53ldqvXOV2q/3laqhKg5BR0B44e0zhFTygSOy/fv12mbOP0bznV8hamzcHqRO0FLFGt/o+H7dEaROgPBFKEJIHR7QR+bfCxzGdv4xWuLsRcbPBKULtFztt8waclp7g9QJEL4IRQiphWVXqjBrkP41Il6FWYO0sOzKULcEAAhTfKYIIVX7Q9U9JeWGrBMAQLhjpQi4LFzs/2+igtIFWs6ugY2Od9HgIHUChC9CEXAZuNi2e3tMZZA6QUtdbNv9QC0PUidA+CIUAZeJ89vu664IRbEdvwMZquJ6K0JdNJjt+ECQ8Jki4DLCilDHx4oQEDrNWimaN2+errnmGnXt2lUJCQm69dZbVVJSElBz+vRpZWdnq0ePHoqLi9P48eNVXl4eUFNaWqrMzEzFxMQoISFBs2bN0tmzgVuKN2/erGHDhslut6tfv37Kzc1t2R0CAAA0QbNC0ZYtW5Sdna13331XeXl5qqqq0pgxY3Ty5EmrZsaMGVq5cqVWrFihLVu2qKysTOPGjbPGz507p8zMTJ05c0bbt2/X0qVLlZubq7lz51o1hw4dUmZmpm644QYVFhYqJydH9957r9avX98KtwwAAFCfzRjT4g8cfP7550pISNCWLVt0/fXXy+fzqVevXlq2bJluu+02SdKBAwc0cOBA5efna9SoUVq7dq1uvvlmlZWVyeVySZKWLFmi2bNn6/PPP1dUVJRmz56t1atXa+/er7+sbMKECaqoqNC6deua1Jvf75fT6ZTP55PD4WjpLQIAgCAK5ev3JX3Q2ufzSZK6d+8uSSooKFBVVZXS09OtmgEDBqhv377Kz8+XJOXn5ystLc0KRJKUkZEhv9+vffv2WTW1r1FTU3ONhlRWVsrv9wccAAAATdXiUFRdXa2cnByNHj1agwef3y3h9XoVFRWl+Pj4gFqXyyWv12vV1A5ENeM1Y43V+P1+nTp1qsF+5s2bJ6fTaR3JycktvTUAABCGWhyKsrOztXfvXr3++uut2U+LzZkzRz6fzzoOHz4c6pYAAEAH0qIt+dOnT9eqVau0detWJSUlWefdbrfOnDmjioqKgNWi8vJyud1uq2bnzp0B16vZnVa7pu6OtfLycjkcDkVHRzfYk91ul93ObwIHAAAt06yVImOMpk+frjfffFMbN25USkpKwPjw4cPVuXNnbdiwwTpXUlKi0tJSeTweSZLH41FRUZGOHj1q1eTl5cnhcCg1NdWqqX2NmpqaawAAALS2Zu0+++Uvf6lly5bpr3/9q/r372+ddzqd1grOtGnTtGbNGuXm5srhcOiBBx6QJG3fvl3S+S35V199tRITE7VgwQJ5vV5NmjRJ9957r5599llJ57fkDx48WNnZ2brnnnu0ceNGPfjgg1q9erUyMjKa1Cu7zwAA6HhC+frdrFBks9kaPP/KK6/orrvuknT+yxsffvhhvfbaa6qsrFRGRoYWLVpkvTUmSZ988ommTZumzZs3KzY2VpMnT9b8+fMVGfn1u3mbN2/WjBkzVFxcrKSkJD3++OPWczQFoQgAgI6nw4SijoRQBABAx9Nhv6cIAADgckEoAgAAEKEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAEqEIAABAkhQZ6gY6kuHDX9R773mtx8OGuVVQ8IsQdgSEnzc0WWd10nocqVj9VEtD2BEQXnr3/pu83irrsdvdWZ99lh7CjlqPzRhjQt1EW/D7/XI6nfL5fHI4HJd8vYiI36ihmbLZpOrqJy75+gAu7lXddsGxLP1PEDsBwpPNtvaCY8aMbZXnaO3X7+bg7bMmGD78xQYDkSQZI33nOy8FtyEgDL2hyY2OL9ddwWkECFO9e/+t0fGkpA1B6qTtEIqaoPZbZg3ZteuzIHUChK/ab5k1pEongtQJEJ5qv2XWkCNHzgSpk7ZDKAIAABChCAAAQBKhqEmGDXM3On7NNb2D1AkQviIV2+h4Z8UFqRMgPLndnRsd79MnKkidtB1CURMUFPxCNlvDYzabtHPn/cFtCAhDF9t2f4dyg9MIEKYutu3+009vDFInbYdQ1ETV1U/UWxG65prebMcHgihL/1NvRaiz4tiODwSJMWPrrQj16RPVatvxQ43vKQIAAO0G31MEAAAQYoQiAAAAEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAkEYoAAAAktSAUbd26VT/60Y+UmJgom82mt956K2DcGKO5c+eqd+/eio6OVnp6ug4ePBhQc+zYMWVlZcnhcCg+Pl5TpkzRiRMnAmo++OADXXfdderSpYuSk5O1YMGC5t8dAABAEzU7FJ08eVLf/va39cc//rHB8QULFuiFF17QkiVLtGPHDsXGxiojI0OnT5+2arKysrRv3z7l5eVp1apV2rp1q+6//35r3O/3a8yYMbriiitUUFCg5557Tk8++aReeumlFtwiAABAE5hLIMm8+eab1uPq6mrjdrvNc889Z52rqKgwdrvdvPbaa8YYY4qLi40ks2vXLqtm7dq1xmazmSNHjhhjjFm0aJHp1q2bqaystGpmz55t+vfv3+TefD6fkWR8Pl9Lbw8AAARZKF+/W/UzRYcOHZLX61V6erp1zul0auTIkcrPz5ck5efnKz4+XiNGjLBq0tPTFRERoR07dlg1119/vaKioqyajIwMlZSU6Msvv2zwuSsrK+X3+wMOAACApmrVUOT1eiVJLpcr4LzL5bLGvF6vEhISAsYjIyPVvXv3gJqGrlH7OeqaN2+enE6ndSQnJ1/6DQEAgLBx2ew+mzNnjnw+n3UcPnw41C0BAIAOpFVDkdvtliSVl5cHnC8vL7fG3G63jh49GjB+9uxZHTt2LKCmoWvUfo667Ha7HA5HwAEAANBUrRqKUlJS5Ha7tWHDBuuc3+/Xjh075PF4JEkej0cVFRUqKCiwajZu3Kjq6mqNHDnSqtm6dauqqqqsmry8PPXv31/dunVrzZYBAAAktSAUnThxQoWFhSosLJR0/sPVhYWFKi0tlc1mU05Ojp5++mm9/fbbKioq0p133qnExETdeuutkqSBAwfqpptu0n333aedO3dq27Ztmj59uiZMmKDExERJ0s9+9jNFRUVpypQp2rdvn9544w0tXLhQM2fObLUbBwAACNDc7WqbNm0ykuodkydPNsac35b/+OOPG5fLZex2u7nxxhtNSUlJwDW++OILM3HiRBMXF2ccDoe5++67zfHjxwNq9uzZY6699lpjt9tNnz59zPz585vVJ1vyAQDoeEL5+m0zxpgQZrI24/f75XQ65fP5+HwRAAAdRChfvy+b3WcAAACXglAEAAAgQhEAAIAkQhEAAIAkQhEAAIAkKTLUDaB9GTTIr+Lirx+npkr79rF7DwCa7PF+0r/+8fXjnt+UfvtR6PpBkxGKYLHZ/PXOFRefP28MwQgALmqarf65f/3j/PnFl+U34FxWePsMks6vEDVmyJDGxwEg7D3er/Hxuf2D0wdajFAESQp4y6whRUXB6QMAOqzab5k15PMPg9MHWoxQBAAAIEIRAACAJEIR/i01tfHxtLTg9AEAHVbPbzY+3utbwekDLUYogqSLb7v/4AN2nwFAoy627f6pkuD0gRYjFMFijKPeilBamtiODwBNtdjUXxHq9S2243cQfE8RArAiBACXiBWhDouVIgAAABGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJBGKAAAAJF3Gv+bDmPO/Z8bv94e4EwAA0FQ1r9s1r+PBdNmGouPHj0uSkpOTQ9wJAABoruPHj8vpdAb1OW0mFFEsCKqrq1VWVqauXbvKZrOFup1W4/f7lZycrMOHD8vh4Je3tjbmt20xv22L+W1bzG/bqpnf0tJS2Ww2JSYmKiIiuJ/yuWxXiiIiIpSUlBTqNtqMw+HgP8o2xPy2Lea3bTG/bYv5bVtOpzNk88sHrQEAAEQoAgAAkEQo6nDsdrueeOIJ2e32ULdyWWJ+2xbz27aY37bF/Lat9jC/l+0HrQEAAJqDlSIAAAARigAAACQRigAAACQRigAAACQRikJi3rx5uuaaa9S1a1clJCTo1ltvVUlJSUDN6dOnlZ2drR49eiguLk7jx49XeXl5QE1paakyMzMVExOjhIQEzZo1S2fPng2o2bx5s4YNGya73a5+/fopNze3rW+vXZk/f75sNptycnKsc8ztpTty5Ih+/vOfq0ePHoqOjlZaWpp2795tjRtjNHfuXPXu3VvR0dFKT0/XwYMHA65x7NgxZWVlyeFwKD4+XlOmTNGJEycCaj744ANdd9116tKli5KTk7VgwYKg3F8onTt3To8//rhSUlIUHR2tb37zm/rtb38b8HugmN+m27p1q370ox8pMTFRNptNb731VsB4MOdyxYoVGjBggLp06aK0tDStWbOm1e832Bqb36qqKs2ePVtpaWmKjY1VYmKi7rzzTpWVlQVco13Nr0HQZWRkmFdeecXs3bvXFBYWmh/+8Iemb9++5sSJE1bN1KlTTXJystmwYYPZvXu3GTVqlPnud79rjZ89e9YMHjzYpKenm/fff9+sWbPG9OzZ08yZM8eq+fjjj01MTIyZOXOmKS4uNv/1X/9lOnXqZNatWxfU+w2VnTt3mm984xtmyJAh5qGHHrLOM7eX5tixY+aKK64wd911l9mxY4f5+OOPzfr1681HH31k1cyfP984nU7z1ltvmT179phbbrnFpKSkmFOnTlk1N910k/n2t79t3n33XfP3v//d9OvXz0ycONEa9/l8xuVymaysLLN3717z2muvmejoaPPiiy8G9X6D7ZlnnjE9evQwq1atMocOHTIrVqwwcXFxZuHChVYN89t0a9asMY8++qj5y1/+YiSZN998M2A8WHO5bds206lTJ7NgwQJTXFxsHnvsMdO5c2dTVFTU5nPQlhqb34qKCpOenm7eeOMNc+DAAZOfn2++853vmOHDhwdcoz3NL6GoHTh69KiRZLZs2WKMOf8HqXPnzmbFihVWzf79+40kk5+fb4w5/wcxIiLCeL1eq2bx4sXG4XCYyspKY4wxjzzyiBk0aFDAc/30pz81GRkZbX1LIXf8+HFz1VVXmby8PPO9733PCkXM7aWbPXu2ufbaay84Xl1dbdxut3nuueescxUVFcZut5vXXnvNGGNMcXGxkWR27dpl1axdu9bYbDZz5MgRY4wxixYtMt26dbPmvOa5+/fv39q31K5kZmaae+65J+DcuHHjTFZWljGG+b0UdV+0gzmXd9xxh8nMzAzoZ+TIkeYXv/hFq95jKDUUOuvauXOnkWQ++eQTY0z7m1/ePmsHfD6fJKl79+6SpIKCAlVVVSk9Pd2qGTBggPr27av8/HxJUn5+vtLS0uRyuayajIwM+f1+7du3z6qpfY2ampprXM6ys7OVmZlZ7/6Z20v39ttva8SIEbr99tuVkJCgoUOH6k9/+pM1fujQIXm93oD5cTqdGjlyZMAcx8fHa8SIEVZNenq6IiIitGPHDqvm+uuvV1RUlFWTkZGhkpISffnll219myHz3e9+Vxs2bNCHH34oSdqzZ4/eeecdjR07VhLz25qCOZfh/HdGbT6fTzabTfHx8ZLa3/wSikKsurpaOTk5Gj16tAYPHixJ8nq9ioqKsv7Q1HC5XPJ6vVZN7RftmvGascZq/H6/Tp061Ra30y68/vrreu+99zRv3rx6Y8ztpfv444+1ePFiXXXVVVq/fr2mTZumBx98UEuXLpX09Rw1ND+15y8hISFgPDIyUt27d2/Wv4fL0a9//WtNmDBBAwYMUOfOnTV06FDl5OQoKytLEvPbmoI5lxeqCZe5ls5/nnP27NmaOHGi9Qtf29v8RjarGq0uOztbe/fu1TvvvBPqVi4Lhw8f1kMPPaS8vDx16dIl1O1clqqrqzVixAg9++yzkqShQ4dq7969WrJkiSZPnhzi7jq+5cuX69VXX9WyZcs0aNAgFRYWKicnR4mJicwvOqyqqirdcccdMsZo8eLFoW7nglgpCqHp06dr1apV2rRpk5KSkqzzbrdbZ86cUUVFRUB9eXm53G63VVN3x1TN44vVOBwORUdHt/bttAsFBQU6evSohg0bpsjISEVGRmrLli164YUXFBkZKZfLxdxeot69eys1NTXg3MCBA1VaWirp6zlqaH5qz9/Ro0cDxs+ePatjx44169/D5WjWrFnWalFaWpomTZqkGTNmWCufzG/rCeZcXqgmHOa6JhB98sknysvLs1aJpPY3v4SiEDDGaPr06XrzzTe1ceNGpaSkBIwPHz5cnTt31oYNG6xzJSUlKi0tlcfjkSR5PB4VFRUF/GGq+cNW84Ll8XgCrlFTU3ONy9GNN96ooqIiFRYWWseIESOUlZVl/TNze2lGjx5d7yskPvzwQ11xxRWSpJSUFLnd7oD58fv92rFjR8AcV1RUqKCgwKrZuHGjqqurNXLkSKtm69atqqqqsmry8vLUv39/devWrc3uL9S++uorRUQE/tXcqVMnVVdXS2J+W1Mw5zJc/86oCUQHDx7U3/72N/Xo0SNgvN3Nb7M+lo1WMW3aNON0Os3mzZvNZ599Zh1fffWVVTN16lTTt29fs3HjRrN7927j8XiMx+Oxxmu2jY8ZM8YUFhaadevWmV69ejW4bXzWrFlm//795o9//GPYbBuvrfbuM2OY20u1c+dOExkZaZ555hlz8OBB8+qrr5qYmBjz3//931bN/PnzTXx8vPnrX/9qPvjgA/PjH/+4wW3OQ4cONTt27DDvvPOOueqqqwK24VZUVBiXy2UmTZpk9u7da15//XUTExNz2W0Zr2vy5MmmT58+1pb8v/zlL6Znz57mkUcesWqY36Y7fvy4ef/99837779vJJn/+I//MO+//761+ylYc7lt2zYTGRlpfve735n9+/ebJ5544rLYkt/Y/J45c8bccsstJikpyRQWFga83tXeSdae5pdQFAKSGjxeeeUVq+bUqVPml7/8penWrZuJiYkxP/nJT8xnn30WcJ1//vOfZuzYsSY6Otr07NnTPPzww6aqqiqgZtOmTebqq682UVFR5sorrwx4jnBRNxQxt5du5cqVZvDgwcZut5sBAwaYl156KWC8urraPP7448blchm73W5uvPFGU1JSElDzxRdfmIkTJ5q4uDjjcDjM3XffbY4fPx5Qs2fPHnPttdcau91u+vTpY+bPn9/m9xZqfr/fPPTQQ6Zv376mS5cu5sorrzSPPvpowIsI89t0mzZtavDv28mTJxtjgjuXy5cvN9/61rdMVFSUGTRokFm9enWb3XewNDa/hw4duuDr3aZNm6xrtKf5tRlT62tSAQAAwhSfKQIAABChCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQBKhCAAAQJL0/wEIkJ9N2k1G0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATAHDD/chailex/anaconda3/envs/eeg/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7203520332374607\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "[2.5684472  3.29182018]\n",
      "-0.7203520332374607\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dd in range(3):\n",
    "    original_data = pd.read_csv(\"../participant_wise_data/participant_{}_data.csv\".format(dd))\n",
    "    data = list()\n",
    "    for i in range(len(original_data)):\n",
    "        temp = list()\n",
    "        temp.append(original_data.iloc[i,0])\n",
    "        temp.append(original_data.iloc[i,1])\n",
    "        list_data = ast.literal_eval(original_data.iloc[i,2])\n",
    "        temp.append(list_data)\n",
    "        temp.append(ast.literal_eval(original_data.iloc[i,3]))\n",
    "        data.append(temp)\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df.iloc[:,2]\n",
    "    y = df.iloc[:,3]\n",
    "\n",
    "    time_series_data = X\n",
    "    targets = y\n",
    "\n",
    "    data = pd.DataFrame({'time_series_data': time_series_data, 'target': targets})\n",
    "\n",
    "    X = np.array(data['time_series_data'].tolist())\n",
    "    y = np.array(data['target'].tolist())\n",
    "    \n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in X:\n",
    "        temp = []\n",
    "        for j in range(len(i)):\n",
    "            temp.append(i[j])\n",
    "        xx.append(temp)\n",
    "    # print(xx[0])\n",
    "\n",
    "    for i in y:\n",
    "        temp = []\n",
    "        for j in range(len(i)):\n",
    "            temp.append(i[j])\n",
    "        yy.append(temp)\n",
    "    # print(yy[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xx, yy, test_size=0.3, random_state=42)\n",
    "\n",
    "    ##################################################################\n",
    "    regr = MLP(hidden_layer_sizes=(512, 256, 128, 2),random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "    pred = regr.predict(X_test)\n",
    "    print(regr.score(X_test, y_test))\n",
    "    # pred = regr.predict(X_test)\n",
    "    # print(pred)\n",
    "    for i in pred:\n",
    "        print(i)\n",
    "    print(regr.score(X_test, y_test))\n",
    "    target_colors = plt.cm.jet(np.linspace(0, 1, 21))\n",
    "\n",
    "    target = [[1,2],[1,8],[2,1],[2,5],[2,9],[3,4],[3,6],[4,3],[4,7],[5,2],[5,5],[5,8],[6,3],[6,7],[7,4],[7,6],[8,1],[8,5],[8,9],[9,2],[9,8]]\n",
    "    color_list = {str([1,2]): target_colors[0],str([1,8]): target_colors[19],str([2,1]): target_colors[2],str([2,5]):target_colors[17],str([2,9]):target_colors[4],str([3,4]):target_colors[15],str([3,6]):target_colors[6],str([4,3]):target_colors[13],str([4,7]):target_colors[8],str([5,2]):target_colors[11],str([5,5]):target_colors[10],str([5,8]):target_colors[9],str([6,3]):target_colors[12],str([6,7]):target_colors[7],str([7,4]):target_colors[14],str([7,6]):target_colors[5],str([8,1]):target_colors[16],str([8,5]):target_colors[3],str([8,9]):target_colors[18],str([9,2]):target_colors[1],str([9,8]):target_colors[20]}\n",
    "\n",
    "    image = cv2.imread('../../new_data_training/points.jpg')\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # scaled_targets = [(int(x * image_width), int(y * image_height)) for x, y in target]\n",
    "\n",
    "    scaled_predicted_points = [(int(x * image_width) if x>-1 else int(x * image_width)*-1, int(y * image_height) if y>-1 else int(y * image_height) *-1) for x, y in pred]\n",
    "    scaled_target_points_color = [color_list[str([int(i[0]),int(i[1])])] for i in y_test]\n",
    "\n",
    "    counter = 0\n",
    "    for point in scaled_predicted_points:\n",
    "        plt.scatter(point[0], point[1], color=scaled_target_points_color[counter], s=5, marker='o')  # Adjust marker size and color as needed\n",
    "        counter += 1\n",
    "\n",
    "    for point in y_test:\n",
    "        plt.scatter(int(point[0] * image_width), int(point[1] * image_height), color=color_list[str(point)], s=25, marker='o')  # Adjust marker size and color as needed\n",
    "\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
